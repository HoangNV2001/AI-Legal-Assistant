# configs/legal_multi_agent_no_web.yml
general:
  use_uvloop: true

embedders:
  llama-3.2-nv-embedqa-1b-v2:
    _type: nim
    base_url: "http://localhost:8016/v1"
    model_name: "nvidia/llama-3.2-nv-embedqa-1b-v2"  # NIM-native; NAT will set input_type for queries

retrievers:
  reg_retriever:
    _type: milvus_retriever
    uri: http://localhost:19530
    collection_name: "vn_regulations"
    embedding_model: llama-3.2-nv-embedqa-1b-v2
    top_k: 5

    vector_field_name: vector
    text_field_name: text
    metadata_fields: [issued_date]
    search_params:
      metric_type: COSINE
      params: { "nprobe": 32 }

functions:
  # --- RAG from Milvus ---
  reg_tool:
    _type: nat_retriever
    retriever: reg_retriever
    topic: Retrieve Vietnamese regulatory documents (decrees, circulars)

  current_time:
    _type: current_datetime
    description: "Return current date-time; DO NOT call this unless explicitly asked."

  # --- Quality-check: sub-agent (react_agent) ---
  answer_quality_check:
    _type: react_agent
    llm_name: vllm_llm
    verbose: false
    tool_names: [current_time]
    additional_instructions: |
      Role: Strict JSON scorer for legal answers.
      Input: ONE-LINE JSON with fields:
        - query (string)
        - draft (string)
        - signals (object) with keys:
            - milvus_hits (int)
            - web_hits (int, optional for no_web)
      Task: Score groundedness, completeness, recency_ok; choose one action among:
        - accept, need_web, need_more_rag
      Output: Return ONLY ONE-LINE JSON with keys:
        groundedness (0..1), completeness (0..1), recency_ok (true/false), action (string), notes (string).
      If REQUIRED fields are MISSING, return ONE-LINE JSON:
        {{"groundedness":0,"completeness":0,"recency_ok":false,"action":"need_more_rag","notes":"missing_fields:[query,draft,signals]"}}
      Do NOT print Thought/Action/Final Answer. Do NOT call any tool. No prose, no code fences.


  # --- Aggregate/Merge context: sub-agent (react_agent) ---
  aggregate_context_llm:
    _type: react_agent
    llm_name: vllm_llm
    verbose: false
    tool_names: [current_time]
    additional_instructions: |
      Role: Context merger for Milvus-only RAG.
      Input: one-line JSON with fields query, milvus_snippets (list of {{text}}), max_tokens (int).
      Task: deduplicate; prefer passages with concrete thresholds, article numbers, effective dates.
      Output: return ONLY one-line JSON with key merged (list of {{text}}).
      Do NOT print Thought/Action/Final Answer. Do NOT call any tool. No prose.

llms:
  vllm_llm:
    _type: openai
    api_key: "EMPTY"
    base_url: "http://localhost:8015/v1"
    model_name: Qwen/Qwen3-8B
    max_tokens: 512
    temperature: 0

workflow:
  _type: react_agent
  llm_name: vllm_llm
  verbose: true
  parse_agent_response_max_retries: 5
  max_tool_calls: 8             # <— chặn vòng lặp dài (gợi ý)
  tool_names:
    - reg_tool
    - answer_quality_check
    - aggregate_context_llm
  additional_instructions: |
    /no_think
    Source policy: BALANCED (no fixed preference). Decide by authority, recency, specificity.
    Scope: Decrees & Circulars only. No speculation.
    Style: Answer in Vietnamese; end with: Đây không phải tư vấn pháp lý.

    HARD RULES (ReAct):
    - The FIRST action MUST be reg_tool (no exceptions).
    - NEVER call answer_quality_check or aggregate_context_llm before a draft exists.
    - When CALLING A TOOL, return EXACTLY 3 lines:
      Thought: LOOKUP
      Action: <reg_tool | answer_quality_check | aggregate_context_llm>
      Action Input: <ONE-LINE valid JSON, no code fences, no newlines>
    - When PRODUCING THE FINAL ANSWER, return EXACTLY 1 line:
      Final Answer: <Vietnamese answer ending with 'Đây không phải tư vấn pháp lý.'>

    VALID EXAMPLES:
    Thought: LOOKUP
    Action: reg_tool
    Action Input: {{"query":"mức phạt vượt đèn đỏ"}}

    Thought: LOOKUP
    Action: web_search_tool
    Action Input: {{"query":"Nghị định xử phạt lỗi vượt đèn đỏ cập nhật 2024 site:chinhphu.vn"}}

eval:
  general:
    output_dir: sizing_output/eval
    dataset:
      _type: json
      file_path: ./data/eval/Legal_agent.json
